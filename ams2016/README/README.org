#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t c:nil
#+OPTIONS: creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+OPTIONS: title:t toc:t todo:t |:t
#+TITLE: AMS 2016: UniCloud, Docker at Unidata
#+SUBTITLE: LDM, TDS, and RAMADDA on Microsoft Azure VM
#+DATE: <2015-12-08 Tue>
#+AUTHOR: Julien Chastang
#+EMAIL: chastang@ucar.edu
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 8.3.2)

#+LATEX_HEADER: \usepackage{bigfoot}
#+LATEX_HEADER: \DeclareNewFootnote{URL}[arabic]
#+LATEX_HEADER: \renewcommand{\href}[2]{#2\footnoteURL{\url{#1}}}

#+SETUPFILE: theme-readtheorg.setup

* Org Export Set up (Internal Only)                                :noexport:

# org-mode stuff. Don't want confirmation for babel exec, nor should babel block be evaluated during export.

#+BEGIN_SRC emacs-lisp :results silent :exports none
  (setq org-confirm-babel-evaluate nil)
  (setq org-export-babel-evaluate nil)
#+END_SRC

#+BEGIN_SRC emacs-lisp :results silent 
  (defun ams2016/org-save-and-export ()
    (interactive)
    (when (eq major-mode 'org-mode)
        (progn
          (org-html-export-to-html)
          (org-md-export-to-markdown)
          (org-latex-export-to-pdf)
          (org-ascii-export-to-ascii))))

  (add-hook 'after-save-hook 'ams2016/org-save-and-export nil t)
#+END_SRC

# Defining the VM we will be work with for the remainder of this org babel session.

#+BEGIN_SRC org :noweb-ref myvm :exports none
unidata-server
#+END_SRC

#+NAME: azure-vm
#+BEGIN_SRC org :results silent :exports none :noweb yes
<<myvm>>
#+END_SRC

# Setting up org babel default arguments for executing =sh= commands below. We will be using tramp for the remote execution. You should have something like this in your ssh-config:

#+BEGIN_SRC sh :eval no :exports none
Host <<myvm>>
    User     ubuntu
    Port     22
    IdentityFile ~/.docker/machine/machines/<<myvm>>/id_rsa
    Hostname <<myvm>>.cloudapp.net
#+END_SRC

# Defaulting to using remote VM. Be careful to specify :dir ~ for the sh blocks where you do not want remote VM execution of commands.

#+BEGIN_SRC emacs-lisp :noweb yes :results silent :exports none
  (setq-local org-babel-default-header-args:sh
              '((:dir . "/ubuntu@<<myvm>>:")))
#+END_SRC

* Preamble

The following instructions describe how to configure a [[https://azure.microsoft.com][Microsoft Azure VM]] serving data with the [[http://www.unidata.ucar.edu/software/ldm/][LDM]], [[http://www.unidata.ucar.edu/software/thredds/current/tds/][TDS]], and [[http://sourceforge.net/projects/ramadda/][RAMADDA]]. This document assumes you have access to Azure resources though these instructions should be fairly similar on other cloud providers (e.g., Amazon). They also assume familiarity with Unix, Docker, and Unidata technology in general. You will have to be comfortable entering command at the Unix command line. We will be using Docker images defined at the [[https://github.com/Unidata/Unidata-Dockerfiles][Unidata-Dockerfiles repository]] in addition to a configuration specifically planned for AMS 2016 demonstrations  project [[https://github.com/Unidata/Unidata-Dockerfiles/tree/master/ams2016][AMS 2016 demonstrations  project]].

:PROPERTIES:
:END:
* Preliminary Setup on Azure

The instructions assume we will create an Azure VM called =unidata-server.cloudapp.net= abbreviated to =unidata-server=. Tailor the VM name for your purposes when following this document. This VM will be our *Docker Host* from where we will run Docker containers for the LDM, TDS, and RAMADDA.

** =docker-machine=

[[https://docs.docker.com/machine/install-machine/][Install]] =docker-machine= on your local computer. =docker-machine= is a command line tool that gives users the ability to create Docker VMs on your local computer or on a cloud provider such as Azure.

** Create a VM on Azure.

The following =docker-machine= command will create a Docker VM on Azure in which you will run various Docker containers. It will take a few minutes to run (between 5 and 10 minutes). You will have to supply =azure-subscription-id= and =azure-subscription-cert= path. See these Azure =docker-machine= [[https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-docker-machine/][instructions]], if you have questions about this process.

# Don't execute the following code block in this buffer; it will take too long. Instead =org-babel-tangle= with a prefix argument; C-u C-c C-v t. Then execute from the command line =/tmp/azure.sh=.

#+BEGIN_SRC org :dir ~ :noweb tangle :tangle /tmp/azure.sh  :exports none :eval no
docker-machine -D create -d azure \
               --azure-subscription-id="3.141" \
               --azure-subscription-cert="/path/to/mycert.pem" \
               --azure-size="ExtraLarge" <<myvm>>
#+END_SRC

#+INCLUDE: "/tmp/azure.sh" src org 

** Configure Unix Shell to Interact with New Azure VM.

Execute the following command in your local computer shell environment.

#+BEGIN_SRC sh :dir ~ :results silent :noweb yes
  eval "$(docker-machine env <<myvm>>)"
#+END_SRC

** =ssh= into VM with =docker-machine=

#+BEGIN_SRC sh :eval no :noweb yes
  docker-machine ssh <<myvm>>
#+END_SRC

# You are about to start running remote execution commands on the Azure VM via tramp. Make sure you can ssh into the VM from the command line to diagnose any potential problems. Also don't forget to tramp clean up connections, if there are problems.

** Install Package(s) with =apt-get=

At the very least, we will need =unzip= on the Azure Docker host.

#+BEGIN_SRC sh  :results verbatim drawer :exports code
  sudo apt-get -qq update
  sudo apt-get -qq install unzip
#+END_SRC

** Add =ubuntu= User to =docker= Group and Restart Docker

#+BEGIN_SRC sh :results verbatim drawer :exports code
  sudo usermod -G docker ubuntu
  sudo service docker restart
#+END_SRC

#+RESULTS:
:RESULTS:
docker stop/waiting
docker start/running, process 29917
:END:

** Restart Azure VM

At this point, we want to restart the VM to get a fresh start. This command may take a little while...

#+BEGIN_SRC sh :dir ~ :noweb yes :results verbatim drawer :exports code
  docker-machine restart <<myvm>>
  eval "$(docker-machine env <<myvm>>)"
#+END_SRC

#+RESULTS:
:RESULTS:
Restarted machines may have new IP addresses. You may need to re-run the `docker-machine env` command.
:END:

** =ssh= into VM

#+BEGIN_SRC sh :dir ~ :eval no :noweb yes
  docker-machine ssh <<myvm>>
#+END_SRC

** Install =docker-compose= on VM

 #+BEGIN_SRC org :noweb-ref dcompose-version :exports none
 1.5.2
 #+END_SRC

=docker-compose= is a tool for defining and running multi-container Docker applications. In our case, we will be running the LDM, TDS, TDM (THREDDS Data Manager) and RAMADDA so =docker-compose= is perfect for this scenario. Install =docker-compose= on the Azure Docker host.

 #+BEGIN_SRC org :noweb yes :results append :exports results
   "You may have to update version (currently at =<<dcompose-version>>=).
 #+END_SRC

 #+RESULTS:
 "You may have to update version (currently at =1.5.2=).

 #+BEGIN_SRC sh :noweb yes :results verbatim drawer :exports code
   curl -L \
  https://github.com/docker/compose/releases/download/<<dcompose-version>>/docker-compose-`uname -s`-`uname -m` \
        > docker-compose
   sudo mv docker-compose /usr/local/bin/
   sudo chmod +x /usr/local/bin/docker-compose
 #+END_SRC

 #+RESULTS:
 :RESULTS:
 :END:

* LDM and TDS Configuration
** Background

At this point, we have done the preliminary legwork to tackle the next step in this process. We will now want to clone two repositories that will allow us to configure and start running the the LDM, TDS, and RAMADDA. In particular, we will be cloning:

  - [[https://github.com/Unidata/Unidata-Dockerfiles][=github.com/Unidata/Unidata-Dockerfiles=]]  
  - [[https://github.com/Unidata/TdsConfig][=github.com/Unidata/TdsConfig=]] 

*** =Unidata-Dockerfiles=

The =Unidata-Dockerfiles= repository contains a number of Dockerfiles that pertain to various Unidata technologies (e.g., the LDM) and also projects (e.g., ams2016). As a matter of background information, a =Dockerfile= is a text file that contains commands to build a Docker image containing, for example, a working LDM. These Docker images can subsequently be run by =docker= command line tools, or =docker-compose= commands that rely on a =docker-compose.yml= file. A =docker-compose.yml= file is a text file that captures exactly how one or more containers run including directory mappings (from outside to within the container), port mappings (from outside to within the container), and other information.

*** =TDSConfig= 

The =TDSConfig= repository is a project that captures THREDDS and LDM configuration files (e.g., =catalog.xml=, =pqact.conf=) for the TDS at [[http://thredds.ucar.edu]]. Specifically, these TDS and LDM configurations were meant to work in harmony with one another. We can re-use this configuration with some minor adjustments for running the TDS on the Azure cloud.

** =git clone= Repositories

With that background information out of the way, let's clone those repositories by creating =~/git= directory where our repositories will live and issuing some =git= commands.

#+BEGIN_SRC sh :results silent
  mkdir -p /home/ubuntu/git
  git clone https://github.com/Unidata/Unidata-Dockerfiles \
      /home/ubuntu/git/Unidata-Dockerfiles
  git clone https://github.com/Unidata/TdsConfig /home/ubuntu/git/TdsConfig
#+END_SRC

** Configuring the LDM
*** LDM Directories on Docker Host

For anyone who has worked with the LDM, you may be familiar with the following directories:

#+BEGIN_EXAMPLE
etc/
var/data
var/logs
var/queue
#+END_EXAMPLE

The LDM =etc= directory is where you will find configuration files related to the LDM including =ldmd.conf=, =pqact= files, =registry.xml=, and  =scour.conf=. We will need the ability to easily observe and manipulate the files from *outside* the running LDM container. To that end, we need to find a home for =etc= on the Docker host. The same is true for the =var/data= and =var/logs= directories. Later, we will use Docker commands that have been written on your behalf to mount these directories from *outside* to within the container. The =var/queues= directory will remain inside the container.

#+BEGIN_SRC sh  :results silent
  mkdir -p ~/var/logs 
  mkdir -p ~/etc/TDS
#+END_SRC

=var/data= is a bit different in that it needs to be mounted on data volume on the Docker host. We will be handling that step further on.

*** LDM Configuration Files

There is a generic set of LDM configuration files located here =~/git/Unidata-Dockerfiles/ldm/etc/=. However, we will just grab =netcheck.conf= which will remain unmodified.

#+BEGIN_SRC sh :results silent :exports code
  cp ~/git/Unidata-Dockerfiles/ldm/etc/netcheck.conf ~/etc
#+END_SRC

The rest of the LDM configuration files will come from our =ams2016= project directory.

Also, remember that these files will be used *inside* the LDM container that we will set up shortly. We will now be working with these files:

- =ldmd.conf=
- =registry.xml=
- =scour.conf=

**** =ldmd.conf=

 #+BEGIN_SRC sh :results silent :exports code
   cp ~/git/Unidata-Dockerfiles/ams2016/ldmd.conf ~/etc/
 #+END_SRC

 This =ldmd.conf= has been setup for the AMS 2016 demonstration serving the following data feeds:
  - [[http://rapidrefresh.noaa.gov/][13km Rapid Refresh]]

 In addition, there is a =~/git/TdConfig/idd/pqacts/README.txt= file that may be helpful in writing a suitable =ldmd.conf= file.

**** =registry.xml=

 #+BEGIN_SRC sh  :results silent :exports code
   cp ~/git/Unidata-Dockerfiles/ams2016/registry.xml ~/etc/
 #+END_SRC

 This file has been set up for the AMS 2016 demonstration. Otherwise you would have to edit the =registry.xml= to ensure the =hostname= element is correct. For your own cloud VMs, work with =support-idd@unidata.ucar.edu= to devise a correct =hostname= element so that LDM statsitics get properly reported. Here is an example =hostname= element =unidata-server.azure.unidata.ucar.edu=.

 #+BEGIN_SRC emacs-lisp :exports none :results silent :noweb yes
   ;; search for the buffer called registry.xml in your emacs session
   (find-file "/ubuntu@<<myvm>>:/home/ubuntu/etc/registry.xml")
 #+END_SRC

**** =scour.conf=

You need to scour data or else your disk will full up. The crontab entry that runs scour is in the [[https://github.com/Unidata/Unidata-Dockerfiles/blob/master/ldm/crontab][LDM Docker container]]. Scouring is invoked once per day.

  #+BEGIN_SRC sh  :results silent
    cp ~/git/Unidata-Dockerfiles/ams2016/scour.conf ~/etc/
  #+END_SRC

**** =pqact.conf= and TDS configuration

In the =ldmd.conf= file we copied just a moment ago there is a reference to a =pqact= file; =etc/TDS/pqact.forecastModels=. We need to ensure that file exists by doing the following instructions. Specifically, explode =~/git/TdsConfig/idd/config.zip= into =~/tdsconfig= and =cp -r= the =pqacts= directory into =~/etc/TDS=. *Note* do NOT use soft links. Docker does not like them.

  #+BEGIN_SRC sh  :results silent
    mkdir -p ~/tdsconfig/
    cp ~/git/tdsConfig/idd/config.zip ~/tdsconfig/
    unzip ~/tdsconfig/config.zip -d ~/tdsconfig/
    cp -r ~/tdsconfig/pqacts/* ~/etc/TDS
  #+END_SRC

**** Edit =ldmfile.sh=

As the top of this file indicates, you must edit the =logfile= to suit your needs. Change the 

#+BEGIN_EXAMPLE
logfile=logs/ldm-mcidas.log
#+END_EXAMPLE

line to

#+BEGIN_EXAMPLE
logfile=var/logs/ldm-mcidas.log
#+END_EXAMPLE

This will ensure =ldmfile.sh= can properly invoked from the =pqact= files.

*** Upstream Data Feed from Unidata or Elsewhere

The LDM operates on a push data model. You will have to find someone who will agree to push you the data. If you are part of the American academic community please send a support email to =support-idd@unidata.ucar.edu= to discuss your LDM data requirements.

** Configuring the TDS
*** Edit TDS catalog.xml Files

The =catalog.xml= files for TDS configuration are contained within the =~/tdsconfig= directory. Search for all files terminating in =.xml= in that directory. Edit the xml files for what data you wish to server. See the [[http://www.unidata.ucar.edu/software/thredds/current/tds/catalog/index.html][TDS Documentation]] for more information on editing these XML files.

  Let's see what is available in the =~/tdsconfig= directory.

  #+BEGIN_SRC sh :results org :exports both
    find ~/tdsconfig -type f -name "*.xml"
  #+END_SRC

  #+RESULTS:
  #+BEGIN_SRC org
  /home/ubuntu/tdsconfig/idd/forecastModels.xml
  /home/ubuntu/tdsconfig/idd/radars.xml
  /home/ubuntu/tdsconfig/idd/obsData.xml
  /home/ubuntu/tdsconfig/idd/forecastProdsAndAna.xml
  /home/ubuntu/tdsconfig/idd/satellite.xml
  /home/ubuntu/tdsconfig/radar/CS039_L2_stations.xml
  /home/ubuntu/tdsconfig/radar/CS039_stations.xml
  /home/ubuntu/tdsconfig/radar/RadarNexradStations.xml
  /home/ubuntu/tdsconfig/radar/RadarTerminalStations.xml
  /home/ubuntu/tdsconfig/radar/RadarL2Stations.xml
  /home/ubuntu/tdsconfig/radar/radarCollections.xml
  /home/ubuntu/tdsconfig/catalog.xml
  /home/ubuntu/tdsconfig/threddsConfig.xml
  /home/ubuntu/tdsconfig/wmsConfig.xml
  #+END_SRC

* Setting up Data Volumes 

As alluded to earlier, we will have to set up data volumes so that the LDM can
write data, and the TDS and RAMADDA can have access to that data. The =/mnt=
volume on Azure is a good place to store data. Check with Azure about the
assurances Azure makes about the reliability of storing your data there for the
long term. For the LDM this should not be too much of a problem, but for RAMADDA
you may wish to be careful.

** Check Free Disk Space

Let's first display the free disk space with the =df= command. 

#+BEGIN_SRC sh :results table drawer :exports both
  df -H
#+END_SRC

#+RESULTS:
:RESULTS:
| Filesystem | Size | Used | Avail | Use% | Mounted                           | on |
| /dev/sda1  | 31G  | 1.8G | 28G   |   6% | /                                 |    |
| none       | 4.1k |    0 | 4.1k  |   0% | /sys/fs/cgroup                    |    |
| udev       | 7.4G |  13k | 7.4G  |   1% | /dev                              |    |
| tmpfs      | 1.5G | 394k | 1.5G  |   1% | /run                              |    |
| none       | 5.3M |    0 | 5.3M  |   0% | /run/lock                         |    |
| none       | 7.4G |    0 | 7.4G  |   0% | /run/shm                          |    |
| none       | 105M |    0 | 105M  |   0% | /run/user                         |    |
| none       | 66k  |    0 | 66k   |   0% | /etc/network/interfaces.dynamic.d |    |
| /dev/sdb1  | 640G |  73M | 607G  |   1% | /mnt                              |    |
:END:

** Create =/data= Directory

Create a =/data= directory where the LDM can write data soft link to the =/mnt= directory. Also, create a =/repository= directory where RAMADDA data will reside.

#+BEGIN_SRC sh :results silent
  sudo ln -s /mnt /data
  sudo mkdir /mnt/ldm/
  sudo chown -R ubuntu:docker /data/ldm
  sudo mkdir /mnt/repository/
  sudo chown -R ubuntu:docker /data/repository
#+END_SRC

These directories will be used by the LDM, TDS, and RAMADDA docker containers when we mount diretories from the Docker host into these containers.

* Opening Ports 

Ensure these ports are open on the VM where these containers will run. Ask the cloud administrator for these ports to be open.

|---------+---------------|
| Service | External Port |
|---------+---------------|
| HTTP    |            80 |
| TDS     |          8080 |
| RAMADDA |          8081 |
| SSL TDM |          8443 |
| LDM     |           388 |
|---------+---------------|

Note the TDM is an application that works in conjuction with the TDS. It creates indexes for GRIB data in the background, and notifies the TDS via port 8443 when data have been updated or changed. See [[https://www.unidata.ucar.edu/software/thredds/current/tds/reference/collections/TDM.html][here]] to learn more about the TDM.

* Tomcat Logging for TDS and RAMADDA

It is a good idea to mount Tomcat logging directories outside the container so that they can be managed for both the TDS and RAMADDA.

#+BEGIN_SRC sh :results silent
  mkdir -p ~/logs/ramadda-tomcat
  mkdir -p ~/logs/tds-tomcat
#+END_SRC

Note there is also a logging directory in =~/tdsconfig/logs=. All these logging directories should be looked at periodically, not the least to ensure that log files are not filling up your system.

* Starting the LDM TDS RAMADDA TDM
*** RAMADDA Preconfiguration

  When you start RAMADDA for the very first time, you must have  a =password.properties= file in the RAMADDA home directory which is =/data/repository/=. See [[http://ramadda.org//repository/userguide/toc.html][RAMADDA documentation]] for more details on setting up RAMADDA. Here is a =pw.properties= file to get you going. Change password below to something more secure!

  #+BEGIN_SRC sh :results silent
    echo ramadda.install.password=changeme! > /data/repository/pw.properties
  #+END_SRC

*** Final Edit to =docker-compose.yml=

When the TDM communicates to the TDS concering changes in data it observes with data supplied by the LDM, it will communicate via the =tdm= tomcat user. Edit the =docker-compose.yml= file and change the =TDM_PW= to =MeIndexer=. This is not as insecure as it would seem since the tdm user has few priviliges. Optimally, one could change the password hash for the TDM user in the =tomcat-users.xml= file.

#+BEGIN_SRC emacs-lisp :exports none :results silent :noweb yes
  ;; search for the buffer called docker-compose.yml in your emacs session
  (find-file "/ubuntu@<<myvm>>:/home/ubuntu/git/Unidata-Dockerfiles/ams2016/docker-compose.yml")
#+END_SRC

*** Pull Down Images from the DockerHub Registry

At this point you are almost ready to run the whole kit and caboodle. But first  pull the relevant docker images to make this easier for the subequent =docker-compose= command.

# Run this command directly on remote host; it takes too long.

#+BEGIN_SRC sh :results silent :eval no
  docker pull unidata/ldmtds:latest
  docker pull unidata/tdm:latest
  docker pull unidata/tds:latest
  docker pull unidata/ramadda:latest
#+END_SRC

*** Start the LDM, TDS, TDM, RAMADDA

We are now finally ready to start the LDM, TDS, TDM, RAMADDA with the following =docker-compose= command.

#+BEGIN_SRC sh :results silent
  docker-compose -f ~/git/Unidata-Dockerfiles/ams2016/docker-compose.yml up -d
#+END_SRC

* Check What is Running 

At this point, you should have these services running:

- LDM
- TDS
- TDM
- RAMADDA

Next, we will check our work through various means.

** Docker Process Status 

From the shell where you started =docker-machine= earlier you can execute the following =docker ps= command to list the containers on your docker host. It should look something like the output below.

#+BEGIN_SRC sh :results table drawer  :exports both
  docker ps --format "table {{.ID}}\t{{.Image}}\t{{.Status}}"
#+END_SRC

#+RESULTS:
:RESULTS:
| CONTAINER    | ID                     | IMAGE | STATUS |      |
| 32d3b20c8329 | unidata/ramadda:latest | Up    |      5 | days |
| 594577bb15b9 | unidata/ldmtds:latest  | Up    |      5 | days |
| d86a3d33216f | unidata/tdm:latest     | Up    |      5 | days |
| 69fc06217d86 | unidata/tds:latest     | Up    |      5 | days |
:END:

** TDS and RAMADDA URLs

#+BEGIN_SRC org :noweb yes :results append :exports results
  Verify what you have the TDS and RAMADDA running by navigating to: [[http://<<myvm>>.cloudapp.net/thredds/catalog.html]] and [[http://<<myvm>>.cloudapp.net:8081/repository]]. If you are going to RAMADDA for the first time, you will have to do some [[http://ramadda.org//repository/userguide/toc.html][RAMADDA set up]].
#+END_SRC

#+RESULTS:
Verify what you have the TDS and RAMADDA running by navigating to: [[http://unidata-server.cloudapp.net/thredds/catalog.html]] and [[http://unidata-server.cloudapp.net:8081/repository]]. If you are going to RAMADDA for the first time, you will have to do some [[http://ramadda.org//repository/userguide/toc.html][RAMADDA set up]].

**  Viewing Data with the IDV 

Another way to verify your work is run the [[https://www.unidata.ucar.edu/software/idv/][Unidata Integrated Data Viewer]].

*** Access TDS with the IDV

#+BEGIN_SRC org :noweb yes :results append :exports results
  In the [[https://www.unidata.ucar.edu/software/idv/docs/userguide/data/choosers/CatalogChooser.html][IDV Dashboard]], you should be able to enter the catalog XML URL: [[http://<<myvm>>.cloudapp.net/thredds/catalog.xml]].  
#+END_SRC

#+RESULTS:
In the [[https://www.unidata.ucar.edu/software/idv/docs/userguide/data/choosers/CatalogChooser.html][IDV Dashboard]], you should be able to enter the catalog XML URL: [[http://unidata-server.cloudapp.net/thredds/catalog.xml]].  

*** Acess RAMADDAA with the IDV

#+BEGIN_SRC org :noweb yes :results append :exports results
RAMADDA has good integration with the IDV and the two technolgies work well together. You may wish to install the [[http://www.unidata.ucar.edu/software/idv/docs/workshop/savingstate/Ramadda.html][RAMADDA IDV plugin]] to publish IDV bundles to RAMADDA. RAMADDA also has access to the =/data/ldm= directory so you may want to set up [[http://ramadda.org//repository/userguide/developer/filesystem.html][server-side view of this part of the file system]]. Finally,  you can enter this catlog URL in the IDV dashbaord to examine data holdings shared bundles, etc. on RAMADDA [[http://unidata-server-2.cloudapp.net:8081/repository?output=thredds.catalog]].
#+END_SRC

#+RESULTS:
RAMADDA has good integration with the IDV and the two technolgies work well together. You may wish to install the [[http://www.unidata.ucar.edu/software/idv/docs/workshop/savingstate/Ramadda.html][RAMADDA IDV plugin]] to publish IDV bundles to RAMADDA. RAMADDA also has access to the =/data/ldm= directory so you may want to set up [[http://ramadda.org//repository/userguide/developer/filesystem.html][server-side view of this part of the file system]]. Finally,  you can enter this catlog URL in the IDV dashbaord to examine data holdings shared bundles, etc. on RAMADDA [[http://unidata-server-2.cloudapp.net:8081/repository?output=thredds.catalog]].


